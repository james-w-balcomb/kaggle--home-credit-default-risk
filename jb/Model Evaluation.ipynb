{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run NB01-Load.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import gc\n",
    "import IPython\n",
    "import lightgbm as lgb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import random \n",
    "#import seaborn as sb\n",
    "import seaborn as sns\n",
    "#import seaborn as snss\n",
    "import scipy\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "from datetime import date\n",
    "from IPython.display import HTML\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import plot_importance\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from patsy import dmatrices\n",
    "from plotly import tools\n",
    "from plotly.offline import init_notebook_mode\n",
    "from plotly.offline import iplot\n",
    "from pylab import rcParams\n",
    "from random import choice\n",
    "from random import choices # Python 3.6+\n",
    "from random import sample\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from xgboost import XGBClassifier\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "plt.rcParams.update({'figure.max_open_warning': 200})\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# In a notebook environment, display the plots inline\n",
    "%matplotlib inline\n",
    "# Set some parameters to apply to all plots. These can be overridden in each plot if desired\n",
    "# Plot size to 14\" x 7\"\n",
    "matplotlib.rc('figure', figsize = (14, 7))\n",
    "# Font size to 14\n",
    "matplotlib.rc('font', size = 14)\n",
    "# Do not display top and right frame lines\n",
    "matplotlib.rc('axes.spines', top = False, right = False)\n",
    "# Remove grid lines\n",
    "matplotlib.rc('axes', grid = False)\n",
    "# Set backgound color to white\n",
    "matplotlib.rc('axes', facecolor = 'white')\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "np.set_printoptions(suppress=True, formatter={'float_kind':'{:f}'.format})\n",
    "\n",
    "#import C:/Development/kaggle--home-credit-default-risk/rand_jitter\n",
    "#import C:/Development/kaggle--home-credit-default-risk/draw_feature_distribution\n",
    "import sys\n",
    "# sys.path.insert(0, 'C:/Development/kaggle--home-credit-default-risk/') # ~= sys.path.prepend\n",
    "sys.path.append('C:/Development/kaggle--home-credit-default-risk/')\n",
    "# import rand_jitter\n",
    "# import draw_feature_distribution\n",
    "##from rand_jitter import * # NOTE: added directly to draw_feature_distribution_v2\n",
    "# from draw_feature_distribution import *\n",
    "# from draw_feature_distribution_v1 import *\n",
    "from draw_feature_distribution_v2 import *\n",
    "\n",
    "# C:\\Users\\jbalcomb\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning:\n",
    "# The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Python version: {}\".format(sys.version))\n",
    "print(\"pandas version: {}\".format(pd.__version__))\n",
    "print(\"NumPy version: {}\".format(np.__version__))\n",
    "print(\"SciPy version: {}\".format(sp.__version__))\n",
    "print(\"scikit-learn version: {}\".format(sklearn.__version__))\n",
    "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
    "print(\"IPython version: {}\".format(IPython.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234567890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Development/kaggle--home-credit-default-risk/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train = pd.read_table(path + 'application_train.csv', sep=',', dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train__ext_source = application_train.loc[:, ['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3','TARGET']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove observations with missing values\n",
    "#application_train__ext_source.dropna(inplace = True)\n",
    "application_train__ext_source__dropna = application_train__ext_source.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#application_train['EXT_SOURCE_AVG'] = application_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe = application_train__ext_source\n",
    "dataframe = application_train__ext_source__dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = array[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234567890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe = application_train__ext_source\n",
    "dataframe = application_train__ext_source__dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = array[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234567890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Confusion Matrix\n",
    "https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unbalanced Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Classification Confusion Matrix\n",
    "dataframe = application_train__ext_source__dropna\n",
    "array = dataframe.values\n",
    "X = array[:,0:2]\n",
    "Y = array[:,3]\n",
    "test_size = 0.33\n",
    "seed = 1234567890\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(matrix)\n",
    "# TP FP\n",
    "# FN TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True-Positive (TP)\n",
    "TP = matrix[0,0]\n",
    "TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False-Positive (FP)\n",
    "FP = matrix[0,1]\n",
    "FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False-Negative (FN)\n",
    "FN = matrix[1,0]\n",
    "FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True-Negative (TN)\n",
    "TN = matrix[1,1]\n",
    "TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy (ACC)\n",
    "# ACC = (TP+TN)/(P+N) = (TP+TN)/(TP+TN+FP+FN)\n",
    "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "# TPR = TP/P = TP/(TP+FN)\n",
    "TPR = TP/(TP+FN)\n",
    "TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specificity or true negative rate (TNR)\n",
    "# TNR = TN/N = TN/(TN+FP)\n",
    "TNR = TN/(TN+FP)\n",
    "TNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision or positive predictive value (PPV)\n",
    "# PPV = TP/(TP+FP)\n",
    "PPV = TP/(TP+FP)\n",
    "PPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative predictive value (NPV)\n",
    "# NPV = TN/(TN+FN)\n",
    "NPV = TN/(TN+FN)\n",
    "NPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miss rate or false negative rate (FNR)\n",
    "# FNR = FN/P = FN/(FN+TP) = 1-TPR\n",
    "FNR = FN/(FN+TP)\n",
    "FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fall-out or false positive rate (FPR)\n",
    "# FPR = FP/N = FP/(FP+TN) = 1-TNR\n",
    "FPR = FP/(FP+TN)\n",
    "FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false discovery rate (FDR)\n",
    "# FDR = FP/(FP+TP) = 1-PPV\n",
    "FDR = FP/(FP+TP)\n",
    "FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false omission rate (FOR)\n",
    "# FOR = FN/(FN+TN) = 1-NPV\n",
    "FOR = FN/(FN+TN)\n",
    "FOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score (...is the harmonic mean of precision and sensitivity)\n",
    "# F1 = 2*((PPV*TPR)/(PPV+TPR)) = 2*TP/(2*TP+FP+FN)\n",
    "F1 = 2*TP/(2*TP+FP+FN)\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matthews correlation coefficient (MCC)\n",
    "# MCC = (TP*TN-FP*FN)/(math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)))\n",
    "MCC = (TP*TN-FP*FN)/(math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)))\n",
    "MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informedness or Bookmaker Informedness (BM)\n",
    "# BM = TPR+TNR-1\n",
    "BM = TPR+TNR-1\n",
    "BM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markedness (MK)\n",
    "# MK = PPV+NPV-1\n",
    "MK = PPV+NPV-1\n",
    "MK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Classification Confusion Matrix\n",
    "dataframe = application_train__ext_source__dropna\n",
    "array = dataframe.values\n",
    "X = array[:,0:2]\n",
    "Y = array[:,3]\n",
    "test_size = 0.33\n",
    "seed = 1234567890\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(matrix)\n",
    "# TP FP\n",
    "# FN TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True-Positive (TP)\n",
    "TP = matrix[0,0]\n",
    "TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False-Positive (FP)\n",
    "FP = matrix[0,1]\n",
    "FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False-Negative (FN)\n",
    "FN = matrix[1,0]\n",
    "FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True-Negative (TN)\n",
    "TN = matrix[1,1]\n",
    "TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy (ACC)\n",
    "# ACC = (TP+TN)/(P+N) = (TP+TN)/(TP+TN+FP+FN)\n",
    "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
    "ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "# TPR = TP/P = TP/(TP+FN)\n",
    "TPR = TP/(TP+FN)\n",
    "TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specificity or true negative rate (TNR)\n",
    "# TNR = TN/N = TN/(TN+FP)\n",
    "TNR = TN/(TN+FP)\n",
    "TNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision or positive predictive value (PPV)\n",
    "# PPV = TP/(TP+FP)\n",
    "PPV = TP/(TP+FP)\n",
    "PPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative predictive value (NPV)\n",
    "# NPV = TN/(TN+FN)\n",
    "NPV = TN/(TN+FN)\n",
    "NPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# miss rate or false negative rate (FNR)\n",
    "# FNR = FN/P = FN/(FN+TP) = 1-TPR\n",
    "FNR = FN/(FN+TP)\n",
    "FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fall-out or false positive rate (FPR)\n",
    "# FPR = FP/N = FP/(FP+TN) = 1-TNR\n",
    "FPR = FP/(FP+TN)\n",
    "FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false discovery rate (FDR)\n",
    "# FDR = FP/(FP+TP) = 1-PPV\n",
    "FDR = FP/(FP+TP)\n",
    "FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false omission rate (FOR)\n",
    "# FOR = FN/(FN+TN) = 1-NPV\n",
    "FOR = FN/(FN+TN)\n",
    "FOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score (...is the harmonic mean of precision and sensitivity)\n",
    "# F1 = 2*((PPV*TPR)/(PPV+TPR)) = 2*TP/(2*TP+FP+FN)\n",
    "F1 = 2*TP/(2*TP+FP+FN)\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matthews correlation coefficient (MCC)\n",
    "# MCC = (TP*TN-FP*FN)/(math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)))\n",
    "MCC = (TP*TN-FP*FN)/(math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)))\n",
    "MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informedness or Bookmaker Informedness (BM)\n",
    "# BM = TPR+TNR-1\n",
    "BM = TPR+TNR-1\n",
    "BM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markedness (MK)\n",
    "# MK = PPV+NPV-1\n",
    "MK = PPV+NPV-1\n",
    "MK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
